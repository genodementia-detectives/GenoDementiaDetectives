{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a78b80-1566-4ae0-9805-83cf6faff548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068001ae-5515-4aec-835f-9c4172789836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce61ad-d727-4ba9-ac39-7d40dccdd0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd9abbf-7a65-43a6-803e-4c0ecee1fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import make_scorer, precision_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "# from plotnine.themes import theme_538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b04d5e-71d0-41cd-9ce1-32d0e167c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def altair_conf_table(conf_df):\n",
    "    '''\n",
    "    Converts dataframe to format suitable for altair and generates a heat map\n",
    "    -----------\n",
    "    Parameters:\n",
    "    conf_df: dataframe\n",
    "    -----------\n",
    "    Returns:\n",
    "    a formatted altair heat map\n",
    "    '''\n",
    "\n",
    "    # Convert the seaborn dataframe to a long-form dataframe suitable for Altair\n",
    "    conf_df_i_long = pd.melt(conf_df.reset_index(), id_vars='index')\n",
    "\n",
    "    # Altair heatmap without legend and axis titles\n",
    "    heatmap = alt.Chart(conf_df_i_long).mark_rect().encode(\n",
    "        x='variable:O',\n",
    "        y='index:O',\n",
    "        color=alt.Color('value:Q', scale=alt.Scale(scheme='blues'),legend=None),  # Set color scale directly\n",
    "        tooltip=['value:N']\n",
    "    ).properties(\n",
    "        width=400,\n",
    "        height=300,\n",
    "        title=\"Confusion Matrix\"\n",
    "    )\n",
    "\n",
    "    # Text layer to display the values in each cell with increased font size\n",
    "    text = alt.Chart(conf_df_i_long).mark_text(baseline='middle', fontSize=16).encode(\n",
    "        x='variable:O',\n",
    "        y='index:O',\n",
    "        text='value:Q'\n",
    "    )\n",
    "\n",
    "    # Combine the heatmap and text layers\n",
    "    alt_chart = heatmap + text\n",
    "\n",
    "    # Remove the color legend\n",
    "    alt_chart = alt_chart.configure_legend(\n",
    "        strokeColor='white',\n",
    "        fillColor='#f5f5f5',\n",
    "        padding=10,\n",
    "        cornerRadius=10,\n",
    "        orient='none',\n",
    "        legendX=650,\n",
    "        legendY=0,\n",
    "        direction='horizontal',\n",
    "        labelFont='Arial',\n",
    "        labelFontSize=12,\n",
    "        labelColor='gray',\n",
    "        title=None\n",
    "    )\n",
    "\n",
    "    # Remove axis titles\n",
    "    alt_chart = alt_chart.configure_axis(\n",
    "        labelFontSize=12,\n",
    "        title=None,\n",
    "        labelAngle=0 \n",
    "    )\n",
    "    \n",
    "\n",
    "    # Show the Altair chart without legend and axis titles\n",
    "    return  alt_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a7f73-461f-432f-b1b7-e937adea21ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323b5db0-fd09-4d4b-95a5-340e02e05211",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a25d91d-dd0b-41f8-a484-4842178651f5",
   "metadata": {},
   "source": [
    "## RNAseq Expression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84fd3fc-0886-48cd-a33e-9c0664ab42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gene RNAseq data file from a parquet formated file\n",
    "table = pq.read_table('../data/processed/merged_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c304d9-9800-4357-9876-743dd2350dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data table to a pandas data frame\n",
    "merged_df = table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1755e15-b05a-4440-a4f5-65675d54b87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete table to free memory\n",
    "del table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2476ba4-46cf-479d-a72a-cbc193745201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ispect the RNAseq dataframe\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee824e-2883-41c2-b5cc-2e1d35c391b6",
   "metadata": {},
   "source": [
    "## Gene Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d1651-e1ac-49ae-a113-374dc100ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene information table\n",
    "rows_genes = pd.read_csv('../data/external/rows-genes.csv')\n",
    "rows_genes = rows_genes.set_index('gene_id')\n",
    "rows_genes.index = rows_genes.index.astype(int)\n",
    "rows_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d73958-86d2-4c7d-bc98-271f0d1b130d",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d445fb0-753c-4c0d-9b56-67794cb621d5",
   "metadata": {},
   "source": [
    "The data was process and tables were merged on the notebook named \"data_import_transformation.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2459a0-c36d-4382-b6a3-47420ea9e85c",
   "metadata": {},
   "source": [
    "## Prepare data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5ae9af-a85a-441f-96e3-e3abe1d1a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # assign X and y by selecting colunmns containing the gene features and predicted value\n",
    "X = merged_df.iloc[:,:50281]\n",
    "y = merged_df['act_demented']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92159669-3d67-49d4-b809-209e1018e5ba",
   "metadata": {},
   "source": [
    "## Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11bce33-a533-4d32-9f74-7a59f16998ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign X and y by selecting colunmns containing the gene features and predicted value\n",
    "X = merged_df.iloc[:,:50281]\n",
    "y = merged_df['act_demented']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4e42c-2f8a-4b5a-b998-1397c37d2758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f15b49-5f9e-445b-a5a0-ee7ffaf28dad",
   "metadata": {},
   "source": [
    "## Scale the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62fb98-1815-48ee-a169-cfb71c5c40aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# standarize training and test set\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5067f2a-7575-4522-8217-4376ab4dbb67",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa2fa01-d0cd-4927-88cc-4e51c4d383c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the logistic regression model\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "logreg_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd1abda-0474-4360-bc9d-38d4ca269a02",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc7b108-2cb4-41f9-86ca-4399eab57b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logreg = logreg_model.predict(X_test_scaled)\n",
    "logreg_score = logreg_model.score(X_test_scaled, y_test)\n",
    "print(\"Logistic regression: {:.2f}\".format(logreg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d108a-3389-4abf-bfe6-852c872bac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, pred_logreg)\n",
    "conf_df = pd.DataFrame(conf_matrix, index=['Actual Dementia', 'Actual No Dementia'],\n",
    "                       columns=['Predicted Dementia', 'Predicted No Dementia'])\n",
    "\n",
    "print(conf_df)\n",
    "\n",
    "# Print a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, pred_logreg))\n",
    "\n",
    "altair_conf_table(conf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steph added\n",
    "def combine_classification_rept(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Input: y_test, y_pred parameters\n",
    "    ---------\n",
    "    Returns: dataframe of classification report\n",
    "    \n",
    "    \"\"\"\n",
    "    rept = classification_report(y_test, y_pred, output_dict=True)\n",
    "    df_cls_rept = pd.DataFrame(rept).T\n",
    "    df_cls_rept = df_cls_rept.round(2)\n",
    "    \n",
    "    #get key rows\n",
    "    df_cls_rpt2 = df_cls_rept.iloc[:2,:]\n",
    "    #df_cls_rept = df_cls_rept.sort_values(by=['f1-score'], ascending=False)\n",
    "    return df_cls_rpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e289a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table for lr w/o tuning\n",
    "df_lr1 = combine_classification_rept(y_test, pred_logreg)\n",
    "df_lr1['model'] = 'Logistical Regression - Default Parameters'\n",
    "#df2 = df1.iloc[:2,:]\n",
    "first_col = df_lr1.pop('model') \n",
    "df_lr1.insert(0, 'model', first_col) \n",
    "df_lr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ca145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table for lr\n",
    "df_lr2 = combine_classification_rept(y_test, best_model_pred)\n",
    "df_lr2['model'] = 'Logistical Regression - best C parameter'\n",
    "first_col = df_lr2.pop('model') \n",
    "df_lr2.insert(0, 'model', first_col) \n",
    "df_lr2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9403578d-c643-487a-996c-96843d8631a8",
   "metadata": {},
   "source": [
    "### Regularization Strength (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ca5163-5ae3-48f8-8053-a4744c916040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define the logistic regression model\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# Define the hyperparameter grid for C\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(logreg_model, param_grid, cv=5, scoring='precision')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameter value\n",
    "best_C = grid_search.best_params_['C']\n",
    "print(f\"Best C value: {best_C}\")\n",
    "\n",
    "# Evaluate the model with the best hyperparameter on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test_scaled, y_test)\n",
    "print(f\"Accuracy on test set with best C: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb84968-287b-4106-bdf6-557d2632d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_pred = best_model.predict(X_test_scaled)\n",
    "best_model_score = best_model.score(X_test_scaled, y_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, best_model_pred)\n",
    "conf_df = pd.DataFrame(conf_matrix, index=['Actual Dementia', 'Actual No Dementia'],\n",
    "                       columns=['Predicted Dementia', 'Predicted No Dementia'])\n",
    "\n",
    "print(conf_df)\n",
    "\n",
    "conf_df_i_long = pd.melt(conf_df.reset_index(), id_vars='index')\n",
    "\n",
    "print(conf_df_i_long)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Print a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, best_model_pred))\n",
    "\n",
    "altair_conf_table(conf_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b817916-fbc0-4234-a317-d04b2ef7eb79",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa745115-6f97-4f91-8de8-1b6d716b63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6722f2a-7bda-4577-826e-430d49b1117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0339a95-9907-4af9-af52-826cadd9969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a85ef-ba44-48c5-ae9c-50385ae34de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame or Series with feature names and their importance scores\n",
    "feature_importance_df = pd.DataFrame(list(feature_importance_dict.items()), columns=['Feature', 'Importance'])\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74c21ae-4c1b-4d23-b3b7-76aa8109d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the 'Feature' column as the index\n",
    "feature_importance_df.set_index('Feature', inplace=True)\n",
    "feature_importance_df.index.name = 'gene_id'\n",
    "feature_importance_df.index = feature_importance_df.index.astype(int)\n",
    "\n",
    "# Display the feature importance DataFrame\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ccc644-8e43-410a-a4d0-fc32c9f9b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_genes = pd.merge(rows_genes, feature_importance_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6a591a-4568-48e8-b9ee-6cef252cd13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f0940a-8c27-48d7-a087-618604f9e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export complet set of genes\n",
    "# rows_genes.to_csv(parent_directory+'/results/tables/all_genes_table.csv')\n",
    "rows_genes.to_csv('../results/tables/all_genes_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bffa98a-4343-4ab7-86c6-197e2b4b7b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "feature_importance_df = feature_importance_df.sort_values(by = 'Importance', ascending = False)\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190ec50e-b868-4cce-ac77-48a6f856768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(feature_importance_df['Importance'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Importance Histogram')\n",
    "plt.xlabel('Importance Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac42b91a-2631-4d58-a9e4-09563acadfcd",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92886092-f6ba-425f-94b6-df63d6e1d576",
   "metadata": {},
   "source": [
    "Removing irrelevant or highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f02f7ad-3606-4177-8230-a83355b6e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# set the number of features\n",
    "max_features = 5000\n",
    "selector = SelectFromModel(model, threshold=-np.inf, max_features=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd311c-8c66-4bb7-b341-b2cb85fdebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many columns at thies point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0729a72d-060c-4da7-959b-52029f3bd84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355d02c4-088c-4480-a1b6-d9ae92483f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb494bc6-4954-4f88-816f-f98cb1afdbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the boolean mask of selected features\n",
    "feature_mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6b596-85bb-4d01-85c5-74b6254636a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use boolean indexing to select the indexes\n",
    "selected_indexes = feature_names[feature_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040de8fe-9536-46eb-96f8-7c9090dc64b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac77bea-b421-4a4f-8df0-53cda6b65011",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = selector.transform(X_train_scaled)\n",
    "X_test_selected = selector.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67ab76-49fc-49bf-8b88-d8387e3ea1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741266a3-c694-4ee3-8a9c-a6df6e3c83cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Perform RFE with cross-validation\n",
    "\n",
    "# Specify the positive class label\n",
    "positive_class_label = 'Dementia'\n",
    "\n",
    "# Create a scorer for precision with the specified positive label\n",
    "precision_scorer = make_scorer(precision_score, pos_label=positive_class_label)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Use the precision_scorer in RFECV\n",
    "rfe = RFECV(estimator=model, step=1, cv=cv, scoring=precision_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb9365e-b9cb-4118-aa14-883da97949d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rfe.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a906c0-0193-41e8-a7a8-f7e1737795d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal number of features\n",
    "optimal_num_features = rfe.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c6116-4cc3-4b8a-8e38-a19b4a1137e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0270cf-156e-45ee-8d59-7c0e7522428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rfe.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c33705-fdaa-4bed-9a00-d180831c7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_features_mask = rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d6df2a-70d1-4f13-986b-03bdb2be4a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_features = selected_indexes[optimal_features_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5e36b-9239-4047-9240-caf5a91f4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of selected features\n",
    "optimal_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64066a-d85a-40c4-aa95-a7bd36f77cda",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Save the array to a file\n",
    "np.save('../results/plots/selected_features.npy', optimal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ea1e1-dac2-4ba0-b2f0-014114a1af83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the data\n",
    "results_df = pd.DataFrame({\n",
    "    'Number_of_Features': range(1, len(rfe.grid_scores_) + 1),\n",
    "    'Cross_Validated_Score': rfe.grid_scores_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bd7a24-c4d9-418e-b358-c9d532551807",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3b131c-1644-46f5-a54e-c65b0b9cb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature importance externally\n",
    "results_df.to_csv('../results/plots/rfe_cv_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41f4ce7-a317-4264-831b-c2c4714953d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the recommendations\n",
    "print(f\"Optimal Number of Features: {optimal_num_features}\")\n",
    "# print(f\"Selected Features: {list(selected_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b60030-6950-4c7f-a65d-c24dd08a2594",
   "metadata": {},
   "source": [
    "#### Plot RFE from external file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6416d44a-7dbe-43a2-a9c1-e14d2861323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_ext = pd.read_csv('../results/plots/rfe_cv_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0f6556-fbb7-448a-b461-ec8e930c6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_ext.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5f3f02-f61d-4bcf-be97-101cb0abedeb",
   "metadata": {},
   "source": [
    "\n",
    "__Recursive Feature Elimination with Cross-Validation__  \n",
    "The plot (RFE-CV) shows the relationship between the number of selected features and the cross-validated score (accuracy in this case). Here's how to interpret the plot:\n",
    "\n",
    "* X-axis (Number of Features Selected):  \n",
    "Each point on the x-axis represents the number of features selected during the RFE process. It starts from 1 and goes up to the total number of features in your dataset.  \n",
    "* Y-axis (Cross-Validated Score):  \n",
    "The y-axis represents the cross-validated score (accuracy in this case) corresponding to the number of features selected. The higher the y-value, the better the model's performance.  \n",
    "\n",
    "* Plot Shape:  \n",
    "The elbow or plateau in the plot is the point where adding more features doesn't significantly improve the cross-validated score. We want to find a balance between the number of features and the model's performance.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb076ee-6989-4a97-bf6d-0d7e6ed32db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'results_df_ext' is your DataFrame\n",
    "\n",
    "\n",
    "alt.themes.enable(\"fivethirtyeight\")\n",
    "\n",
    "# Create Altair chart with attribute syntax\n",
    "chart = alt.Chart(data=results_df_ext, width=600).mark_line(point=True)\n",
    "\n",
    "chart = chart.encode(\n",
    "    x=alt.X('Number_of_Features:O', \n",
    "            axis=alt.Axis(ticks=True, labels=True, \n",
    "                          values=list(range(0, max_features+1, 100)), \n",
    "                          title='Number of Features',\n",
    "                          grid=True,  # Show gridlines\n",
    "                          domain=False,  # Hide x-axis line\n",
    "                          labelAlign='right',  # Align labels to the right for better readability\n",
    "                          labelPadding=0,  # Add padding to labels\n",
    "                          tickMinStep=100)  # Set the interval between ticks\n",
    "           ),\n",
    "    y=alt.Y('Cross_Validated_Score:Q',\n",
    "           axis=alt.Axis(title='Cross Validation Score')),\n",
    "    tooltip=['Number_of_Features:O', 'Cross_Validated_Score:Q']\n",
    ")\n",
    "\n",
    "chart = chart.properties(\n",
    "    title='Recursive Feature Elimination with Cross-Validation (RFE-CV)'  # Add the title here\n",
    ")\n",
    "\n",
    "# Add a vertical red line to represent optimal_num_features\n",
    "red_line = alt.Chart(pd.DataFrame({'x': [optimal_num_features]})).mark_rule(color='red').encode(x='x:O')\n",
    "\n",
    "# Combine the main chart and the red line\n",
    "combined_chart = chart + red_line\n",
    "\n",
    "# Show the chart\n",
    "combined_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a26d8f-dd2d-44e8-83ed-cff86c42a40d",
   "metadata": {},
   "source": [
    "#### Most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919fc8b3-0611-4469-beae-15fa07955934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read selected features\n",
    "optimal_features = np.load('../results/plots/selected_features.npy' , allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cef191-9819-4328-8fe2-e37209baea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert index key to integers for feature matching\n",
    "optimal_features = optimal_features.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761c88db-65cb-4ccd-8d64-136a46488f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge selected features with gene information data\n",
    "selected_rows = rows_genes [rows_genes .index.isin(optimal_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f91225-2671-496f-bbac-cf4a92a60f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect selected gene rows/features\n",
    "selected_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d598c-b77b-4a74-8e96-6f24f1c62a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export selected genes table\n",
    "selected_rows.to_csv('../results/tables/selected_genes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee73a16-cc1f-4686-962c-424d419d2489",
   "metadata": {},
   "source": [
    "## Model performace with reduced selcted features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3dbc2b-a639-409a-b952-208b1faed71a",
   "metadata": {},
   "source": [
    "Let's compare how a model trained with all features performs when conpared with a model that was only trained with the selected features based on RFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75803082-6216-4c57-9734-eb7c074ae08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prime = X_train[optimal_features.astype(str)]\n",
    "X_test_prime = X_test[optimal_features.astype(str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66e904-bd72-4aa1-8e6a-47499677b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# standarize training and test set\n",
    "X_train_i_scaled = scaler.fit_transform(X_train_prime)\n",
    "X_test_i_scaled = scaler.transform(X_test_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea573e46-0144-4a68-9620-00e9931451d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the logistic regression model\n",
    "logreg_model_i = LogisticRegression(random_state=42 ,C=0.001 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d30d86e-5e17-403d-b307-852cb2b179ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model_i.fit(X_train_i_scaled, y_train)\n",
    "\n",
    "pred_logreg_i = logreg_model_i.predict(X_test_i_scaled)\n",
    "logreg_score_i = logreg_model_i.score(X_test_i_scaled, y_test)\n",
    "print(\"Logistic regression: {:.2f}\".format(logreg_score_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7285e2dd-a813-44b0-a4e0-997b9f98b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_i = confusion_matrix(y_test, pred_logreg_i)\n",
    "conf_df_i = pd.DataFrame(conf_matrix_i, index=['Actual Dementia', 'Actual No Dementia'],\n",
    "                       columns=['Predicted Dementia', 'Predicted No Dementia'])\n",
    "\n",
    "print(conf_df_i)\n",
    "\n",
    "# Print a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, pred_logreg_i))\n",
    "\n",
    "alt.themes.enable(\"default\")\n",
    "altair_conf_table(conf_df_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a2e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table for lr\n",
    "df_lr3 = combine_classification_rept(y_test, pred_logreg_i)\n",
    "df_lr3['model'] = \"Logistical regression - reduced features\"\n",
    "#df2 = df1.iloc[:2,:]\n",
    "first_col = df_lr3.pop('model') \n",
    "df_lr3.insert(0, 'model', first_col) \n",
    "df_lr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a7769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined =pd.concat([df_lr1,df_lr2,df_lr3])\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07907a61-ba33-4f0c-aecd-ab9f566074bd",
   "metadata": {},
   "source": [
    "### Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e306671-3ab1-4832-93f3-3eaba46538a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Solver\n",
    "\n",
    "# Define the solvers you want to compare\n",
    "solvers = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "\n",
    "# Initialize an empty dictionary to store the mean cross-validation scores for each solver\n",
    "mean_scores = {}\n",
    "\n",
    "# Loop through each solver and calculate the mean cross-validation score\n",
    "for solver in solvers:\n",
    "    model = LogisticRegression(random_state=42,C=0.001,solver=solver)\n",
    "                               \n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')  # You can use other scoring metrics as well\n",
    "    mean_scores[solver] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4750dea9-d941-44ee-9d57-81349a9fe5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print mean scores for each solver\n",
    "for solver, mean_score in mean_scores.items():\n",
    "    print(f'{solver}: {mean_score}')\n",
    "\n",
    "# Choose the solver with the highest mean score\n",
    "best_solver = max(mean_scores, key=mean_scores.get)\n",
    "print(f'Best Solver: {best_solver}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed707943-24a8-4155-b00c-046e0f068d16",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaef445-3e4f-41d7-a869-2c37545d724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(random_state=42 ,C=0.001, solver='lbfgs' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15fa797-c53c-483e-a7c4-887ed72fbb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model.fit(X_train_i_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdafdab7-56db-4b9b-82a2-152c937f570e",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e17778a-2e12-4462-966e-b087f61c7393",
   "metadata": {},
   "source": [
    "When working with an small data set we need to awared that we do not ovorfit ther model. In such a case the model may learn the noise in the data rather than the actual patterns on the data. In order to check for overfitting we used cross-validation to det4ermone the model's performance on multiple train-test splits. If the model consistently performs well across different subsets of the data, it's a positive sign that the model's performance is not dependent on a specific random split of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf557b0a-98b4-4ab6-8ee1-bc8e8d1454cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logistic regression model with chosen parameters\n",
    "logreg_model = LogisticRegression(random_state=42, C=0.001, solver='lbfgs',\n",
    "                                  max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760fdbe9-23b2-44b2-8dc2-704cd6b8b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with standard scaling (if applicable) and the model\n",
    "model_pipeline = make_pipeline(StandardScaler(), logreg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d20e69-9054-4547-9852-1627f5b0ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=12, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d4527-9622-45e9-88e2-6b2398bf9a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd33528b-df63-45ad-a798-67f9f6e9d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore FutureWarnings and all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Perform cross-validation and get the scores\n",
    "train_scores = cross_val_score(model_pipeline, X, y,\n",
    "                               cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "test_scores = cross_val_score(logreg_model, X, y,\n",
    "                              cv=cv, scoring='accuracy', n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5578e048-7520-4984-9af9-2d53bcf86b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Fold': np.arange(1, len(train_scores) + 1),\n",
    "    'Train Accuracy': train_scores,\n",
    "    'Test Accuracy': test_scores\n",
    "})\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a9eeb-b85f-47dd-bed2-f59123719562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results_df['Fold'], results_df['Train Accuracy'], marker='o', label='Train Accuracy')\n",
    "plt.plot(results_df['Fold'], results_df['Test Accuracy'], marker='o', label='Test Accuracy')\n",
    "plt.title('Cross-Validation Results')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374aacc-5f93-42a4-9ccb-7f0f6ce8263a",
   "metadata": {},
   "source": [
    "In general, the training accuracies are reasonably high wich indicats that the model is learning from the training data. However, there is some variability in the accuracies across the different folds.\n",
    "The test accuracies are lower than the training accuracies which may be expected however the differences in accuracy across the various folds might indicate some level of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f7837-d95b-4b31-ab90-b096d1884c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0eedcaa-49ea-4194-adeb-5f2102925680",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90a6399-b05b-4346-8bd3-ffdb77e9b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7849a6bc-e29c-4f8d-b956-0ba89cffbcc4",
   "metadata": {},
   "source": [
    "## Discusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a757c6f1-6739-40d0-8997-5f77fb0d3e7c",
   "metadata": {},
   "source": [
    "Regarding long-term care insurance underwriting, our primary goal is to enhance the accuracy of predicting No Dementia in patients while minimizing false positives. The original model, which uses over 50,000 features, has a greater precision of 0.85 for No Dementia, indicating that 85% of patients identified as No Dementia are accurate. In contrast, the new model has a precision of approximately 0.76 for No Dementia, meaning that around 76% of instances predicted as No Dementia are true negatives.\n",
    "Although the new model correctly identifies more true negatives (35 out of 41) than the original model (34 out of 41), the precision metric considers the ratio of true negatives to false positives. The original model achieves a higher precision in predicting No Dementia, indicating a lower occurrence of false positives.\n",
    "It's important to acknowledge that despite utilizing only 283 features or the expression of 283 genes, the new model achieves a comparable specificity for predicting No Dementia. This reduction in feature dimensionality has practical implications, such as reduced computational costs and improved model interpretability.\n",
    "Furthermore, the possibility of obtaining gene expression data on 283 targeted genes using faster chip technology, such as customized microarrays or targeted RNA sequencing panels, is worth investigating. These technologies allow for high-throughput analysis, offering opportunities for more efficient and streamlined processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fa29f5-95fe-472a-9c72-3276fd1584d8",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8900b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "\n",
    "def get_library_versions():\n",
    "    \"\"\"\n",
    "    input list of library names as str\n",
    "    ----------\n",
    "    return dictionary with k,v as library,version\n",
    "    \"\"\"\n",
    "    # List of libraries used in the project\n",
    "    libraries = ['pandas', 'numpy', 'altair', 'pyarrow', 'scikit-learn', 'seaborn', 'matplotlib', 'warnings']\n",
    "\n",
    "    # Dictionary to store library versions\n",
    "    library_versions = {}\n",
    "\n",
    "    # Iterate through the list of libraries and get their versions\n",
    "    for library in libraries:\n",
    "        try:\n",
    "            version = pkg_resources.get_distribution(library).version\n",
    "            library_versions[library] = version\n",
    "        except pkg_resources.DistributionNotFound:\n",
    "            library_versions[library] = \"Not Installed\"\n",
    "\n",
    "    return library_versions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    versions = get_library_versions()\n",
    "\n",
    "    # Print the library versions\n",
    "    print(\"Library Versions:\")\n",
    "    for library, version in versions.items():\n",
    "        print(f\"{library}: {version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765e6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
